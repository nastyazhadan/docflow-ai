# DocFlow AI - Docker Compose конфигурация
#
# ⚠️ ВАЖНО: Перед запуском необходимо установить Ollama локально!
# 1. Установите Ollama: https://ollama.com/
# 2. Установите модели: ollama pull gemma3:4b && ollama pull nomic-embed-text
# 3. Убедитесь что Ollama запущен: curl http://localhost:11434/api/version
#
# Система работает ТОЛЬКО локально с Ollama (без OpenAI).

services:
  n8n:
    image: n8nio/n8n:latest
    restart: unless-stopped
    ports:
      - "5678:5678"
    environment:
      - N8N_HOST=localhost
      - N8N_PORT=5678
      - N8N_PROTOCOL=http
      - NODE_ENV=production
    volumes:
      - n8n_data:/home/node/.n8n
    networks:
      - app-net

  scraper-service:
    build:
      context: ./services/scraper
    restart: unless-stopped
    ports:
      - "8000:8000"
    environment:
      - SCRAPER_ROOT_DIR=/data/docs
    volumes:
      - ./data:/data/docs:ro
    networks:
      - app-net

  cleaner-service:
    build:
      context: ./services/cleaner
    restart: unless-stopped
    ports:
      - "8001:8000"
    networks:
      - app-net

  normalizer-service:
    build:
      context: ./services/normalizer
    restart: unless-stopped
    ports:
      - "8002:8000"
    networks:
      - app-net

  indexer-service:
    build:
      context: ./services/indexer
    restart: unless-stopped
    ports:
      - "8003:8000"
    environment:
      - API_HOST=api
      - API_PORT=8000
    depends_on:
      - api
    networks:
      - app-net

  api:
    build:
      context: .
      dockerfile: ./api/Dockerfile
    restart: unless-stopped
    ports:
      - "8004:8000"
    environment:
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - LLM_PROVIDER=${LLM_PROVIDER:-ollama}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-gemma3:4b}
      - OLLAMA_EMBEDDING_MODEL=${OLLAMA_EMBEDDING_MODEL:-nomic-embed-text}
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://host.docker.internal:11434}
      - EMBEDDING_DIMENSION=${EMBEDDING_DIMENSION:-768}
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      - qdrant
    networks:
      - app-net

  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    restart: unless-stopped
    ports:
      - "6333:6333"   # HTTP API
      - "6334:6334"   # gRPC (может пригодиться позже)
    volumes:
      - ./qdrant_data:/qdrant/storage
    networks:
      - app-net

networks:
  app-net:
    driver: bridge

volumes:
  n8n_data:
