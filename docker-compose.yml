# DocFlow AI - Docker Compose конфигурация
#
# ⚠️ ВАЖНО: Перед запуском необходимо установить Ollama локально!
# 1. Установите Ollama: https://ollama.com/
# 2. Установите модели: p && ollama pull nomic-embed-text
# 3. Убедитесь что Ollama запущен: curl http://localhost:11434/api/version
#
# Система работает ТОЛЬКО локально с Ollama (без OpenAI).

services:
  n8n:
    image: n8nio/n8n:latest
    restart: unless-stopped
    ports:
      - "5678:5678"
    environment:
      - N8N_HOST=localhost
      - N8N_PORT=5678
      - N8N_PROTOCOL=http
      - NODE_ENV=production
    volumes:
      - n8n_data:/home/node/.n8n
    networks:
      - app-net

  scraper-service:
    build:
      context: ./services/scraper
    restart: unless-stopped
    ports:
      - "8000:8000"
    networks:
      - app-net

  cleaner-service:
    build:
      context: ./services/cleaner
    restart: unless-stopped
    ports:
      - "8001:8000"
    networks:
      - app-net

  normalizer-service:
    build:
      context: ./services/normalizer
    restart: unless-stopped
    ports:
      - "8002:8000"
    networks:
      - app-net

  indexer-service:
    build:
      context: ./services/indexer
    restart: unless-stopped
    ports:
      - "8003:8000"
    environment:
      - API_HOST=api
      - API_PORT=8000
    depends_on:
      - api
    networks:
      - app-net

  api:
    build:
      context: .
      dockerfile: core_api/Dockerfile
    restart: unless-stopped
    ports:
      - "8004:8000"
    environment:
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - LLM_PROVIDER=${LLM_PROVIDER:-ollama}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-gemma3:4b}
      - OLLAMA_EMBEDDING_MODEL=${OLLAMA_EMBEDDING_MODEL:-nomic-embed-text}
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://host.docker.internal:11434}
      - EMBEDDING_DIMENSION=${EMBEDDING_DIMENSION:-768}
      - DATABASE_URL=${DATABASE_URL}
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - app-net
    volumes:
      - ./core_api:/app/core_api
    depends_on:
      - qdrant
      - postgres

  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    restart: unless-stopped
    ports:
      - "6333:6333"   # HTTP API
      - "6334:6334"   # gRPC (может пригодиться позже)
    volumes:
      - .infrastructure/volumes/qdrant_data:/qdrant/storage
    networks:
      - app-net

  postgres:
    image: postgres:16-alpine
    restart: unless-stopped
    environment:
      - POSTGRES_DB=docflow
      - POSTGRES_USER=docflow
      - POSTGRES_PASSWORD=docflow
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - app-net
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U docflow -d docflow" ]
      interval: 5s
      timeout: 5s
      retries: 10

networks:
  app-net:
    driver: bridge

volumes:
  n8n_data:
  postgres_data:
